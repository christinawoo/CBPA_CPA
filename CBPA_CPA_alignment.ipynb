{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AZn4dM-9v1fJ"
   },
   "outputs": [],
   "source": [
    "### To use brainpy\n",
    "### 1. run this part\n",
    "# ! pip install cython\n",
    "# ! git clone https://github.com/mobiusklein/brainpy.git\n",
    "# % cd ./brainpy\n",
    "# ! python setup.py install\n",
    "# % cd ..\n",
    "\n",
    "### 2. restart runtime\n",
    "\n",
    "### 3. run this part\n",
    "from brainpy import isotopic_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zH_NysNyQXY9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pyteomics.mzml import read as mzmlRead\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pyteomics.mass import Composition\n",
    "from brainpy import isotopic_variants\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "import time\n",
    "\n",
    "import os\n",
    "working_directory_path = '/content/DKM102+DKM106'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bPigSJN-QXZc"
   },
   "outputs": [],
   "source": [
    "def parseSpectra(vendormzmlFilePath, featureDF):\n",
    "    # sort feature dataframe by retention time (RT) and in ascending order\n",
    "    featureDF = featureDF.sort_values('rt', ascending = True).reset_index(drop = True)\n",
    "    # data structure for recording peaks to monitor\n",
    "    monitorDict = {}\n",
    "    finishedDict = {}\n",
    "    # position pointer\n",
    "    posPeakList = 0\n",
    "    # loop through each scan\n",
    "    for scan in mzmlRead(vendormzmlFilePath):\n",
    "        # only process MS1\n",
    "        if scan['ms level'] != 1:\n",
    "            continue\n",
    "        # feature extraction\n",
    "        scanRT = scan['scanList']['scan'][0]['scan start time']\n",
    "        # if new feature reached, register it\n",
    "        while posPeakList < featureDF.shape[0] and scanRT > (featureDF.loc[posPeakList, 'rt']-0.5):\n",
    "            # register in monitor dictionary\n",
    "            monitorDict[(posPeakList, \n",
    "                         str(round(featureDF.loc[posPeakList, 'mz'], 4)),\n",
    "                        featureDF.loc[posPeakList, 'charge'])] = []\n",
    "            # advance position pointer\n",
    "            posPeakList += 1\n",
    "        # detect if any feature in monitor dictionary is finished\n",
    "        # loop through each peak in monitor dictionary\n",
    "        finishedList = []\n",
    "        for posFeature, mzFeature, chargeFeature in monitorDict.keys():\n",
    "            # if retention time end is passed\n",
    "            if (featureDF.loc[posFeature, 'rt']+0.5) < scanRT:\n",
    "                # register it for later removal\n",
    "                finishedList.append((posFeature, mzFeature, chargeFeature))\n",
    "            # else, propagate the features\n",
    "            else:\n",
    "                # add new feature to monitor list\n",
    "                # first, get relevant peaks\n",
    "                intArray = scan['intensity array']\n",
    "                mzArray = scan['m/z array']\n",
    "                targetMz = featureDF.loc[posFeature, 'mz']\n",
    "                targetCharge = featureDF.loc[posFeature, 'charge']\n",
    "                mzLowerBound = targetMz-3\n",
    "                mzUpperBound = targetMz+3\n",
    "                try:\n",
    "                    indexPeakStart = min([i for i, mz in enumerate(mzArray) if mz > mzLowerBound])\n",
    "                    indexPeakEnd = max([i for i, mz in enumerate(mzArray) if mz < mzUpperBound])\n",
    "                except:\n",
    "                    continue\n",
    "                # debug\n",
    "                if indexPeakStart > indexPeakEnd:\n",
    "                    continue\n",
    "                intArrayRelevant = intArray[indexPeakStart:indexPeakEnd+1]\n",
    "                mzArrayRelevant = mzArray[indexPeakStart:indexPeakEnd+1]\n",
    "                # second, register it\n",
    "                monitorDict[(posFeature, mzFeature, chargeFeature)].append(\\\n",
    "                    (list(mzArrayRelevant), list(intArrayRelevant), scanRT))\n",
    "        # move finished feature to another dictionary\n",
    "        for key in finishedList:\n",
    "            if len(monitorDict[key]) > 0:\n",
    "                finishedDict[key] = monitorDict[key]\n",
    "            del monitorDict[key]\n",
    "    # final process: move all remaining feature into finished dictionary\n",
    "    for key in monitorDict.keys():\n",
    "        finishedDict[key] = monitorDict[key]\n",
    "    # return\n",
    "    return finishedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XLr8pQ9LM_8Z"
   },
   "outputs": [],
   "source": [
    "def separateSignalNoise(finishedDict, filterOut = True):\n",
    "    # separate signal and noise and discard signal spectrum with fewer than 3 peaks\n",
    "    separatedDict = {}\n",
    "    for key in finishedDict.keys():\n",
    "        # initialize empty containers\n",
    "        signalList = []\n",
    "        noiseList = []\n",
    "        # get current spectrum list\n",
    "        spectrumList = finishedDict[key]\n",
    "        # process each spectrum in the list\n",
    "        for spectrum in spectrumList:\n",
    "            # separate signal and noise\n",
    "            signalSpectrum, noiseSpectrum = separateSignalNoiseFunc(key, spectrum)\n",
    "            # keep those pairs whose signal has more than 1 peaks\n",
    "            if len(signalSpectrum[0]) >= 1:\n",
    "                signalList.append(signalSpectrum)\n",
    "                noiseList.append(noiseSpectrum)\n",
    "        # register\n",
    "        if filterOut == False:\n",
    "            separatedDict[key] = {'signal':signalList, 'noise':noiseList}\n",
    "        elif len(signalList) > 0:\n",
    "            separatedDict[key] = {'signal':signalList, 'noise':noiseList}\n",
    "    # return\n",
    "    return separatedDict\n",
    "\n",
    "def separateSignalNoiseFunc(masterKey, spectrum):\n",
    "    # findInPhasePeaks(keyMz, PDMode, mzArray)\n",
    "    # noise is defined as out-of-phase peaks\n",
    "    # anything that is in-phase should be considered as signal\n",
    "    # even if it is of low intensity, unexpected, ..., etc.\n",
    "    indexSignal = findInPhasePeaks(masterKey[1], 1./float(masterKey[2]), spectrum[0])\n",
    "    indexNoise = list(set(range(len(spectrum[0]))).difference(set(indexSignal)))\n",
    "    # separate signal from noise\n",
    "    mzSignalArray = []\n",
    "    intSignalArray = []\n",
    "    mzNoiseArray = []\n",
    "    intNoiseArray = []\n",
    "    for index in indexSignal:\n",
    "        mzSignalArray.append(spectrum[0][index])\n",
    "        intSignalArray.append(spectrum[1][index])\n",
    "    for index in indexNoise:\n",
    "        mzNoiseArray.append(spectrum[0][index])\n",
    "        intNoiseArray.append(spectrum[1][index])\n",
    "    # coerse to numpy array\n",
    "    mzSignalArray = np.array(mzSignalArray)\n",
    "    intSignalArray = np.array(intSignalArray)\n",
    "    mzNoiseArray = np.array(mzNoiseArray)\n",
    "    intNoiseArray = np.array(intNoiseArray)\n",
    "    return (mzSignalArray, intSignalArray, spectrum[2]),\\\n",
    "        (mzNoiseArray, intNoiseArray, spectrum[2])\n",
    "\n",
    "def findInPhasePeaks(keyMz, PDMode, mzArray):\n",
    "    # convert string to float\n",
    "    keyMz = float(keyMz)\n",
    "    # find only consecutive inphase peaks\n",
    "    # conversion\n",
    "    mzArray = np.array(mzArray)\n",
    "    inPhasePeakList = []\n",
    "    # register keyMz\n",
    "    minDiffIndex = np.argmin(np.abs(mzArray-keyMz))\n",
    "    if not withinTol(mzArray[minDiffIndex], keyMz):\n",
    "        return []\n",
    "    inPhasePeakList.append(minDiffIndex)\n",
    "    # search forward\n",
    "    distInt = 1\n",
    "    newMz = keyMz-distInt*PDMode\n",
    "    while newMz >= np.min(mzArray):\n",
    "        minDiffIndex = np.argmin(np.abs(mzArray-newMz))\n",
    "        if withinTol(mzArray[minDiffIndex], newMz):\n",
    "            inPhasePeakList.append(minDiffIndex)\n",
    "        else:\n",
    "            break\n",
    "        distInt += 1\n",
    "        newMz = keyMz-distInt*PDMode\n",
    "    # search backward\n",
    "    distInt = 1\n",
    "    newMz = keyMz+distInt*PDMode\n",
    "    while newMz <= np.max(mzArray):\n",
    "        minDiffIndex = np.argmin(np.abs(mzArray-newMz))\n",
    "        if withinTol(mzArray[minDiffIndex], newMz):\n",
    "            inPhasePeakList.append(minDiffIndex)\n",
    "        distInt += 1\n",
    "        newMz = keyMz+distInt*PDMode\n",
    "    # return\n",
    "    return sorted(inPhasePeakList)\n",
    "\n",
    "def withinTol(a, b):\n",
    "    c = np.mean([a, b])\n",
    "    diff = np.abs(a-b)\n",
    "    errorPPM = float(diff)/float(c)*1e6\n",
    "    if errorPPM > 20:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IxJtcedb_DLQ"
   },
   "outputs": [],
   "source": [
    "def quickBrainpyRegularFit(targetSpectrum, seq, charge, probeType):\n",
    "    # get composition from sequence\n",
    "    c = Composition(sequence = seq.upper())\n",
    "    # get peak from brainpy\n",
    "    mzList = []\n",
    "    intList = []\n",
    "    for peak in isotopic_variants(c, charge = charge):\n",
    "        mzList.append(peak.mz)\n",
    "        intList.append(peak.intensity)\n",
    "    # sort peak\n",
    "    mzArray = np.array(mzList)\n",
    "    intArray = np.array(intList)\n",
    "    orderKey = np.argsort(mzArray)\n",
    "    mzArray = mzArray[orderKey]\n",
    "    intArray = intArray[orderKey]\n",
    "    # filter\n",
    "    indexKeep = intArray >= 0.01*np.max(intArray)\n",
    "    mzArray = mzArray[indexKeep]\n",
    "    intArray = intArray[indexKeep]\n",
    "    # add modification mass\n",
    "    mzArray += seq.count('c')*57.02146/charge # carbamidomethyl Cys\n",
    "    mzArray += 124.0838/charge # isotag C13\n",
    "    if probeType == 'CBPA':\n",
    "        mzArray += 77.0265/charge # account for CBA/CBPA mass difference\n",
    "    # scale\n",
    "    intArray *= np.max(targetSpectrum[1])/np.max(intArray)\n",
    "    # return\n",
    "    return (mzArray, intArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Fq75jr1yyYt-"
   },
   "outputs": [],
   "source": [
    "def wrapperFunc(allDF, CBAmzmlPath, CBPAmzmlPath):\n",
    "    ### MS2 RT approach\n",
    "    DF = allDF.loc[(allDF['Confidence'] == 'High')\\\n",
    "                      & (allDF['Modifications'].apply(lambda s: pd.notnull(s) and 'si' in s.lower()))]\n",
    "    alignDF = DF.sort_values(by = 'XCorr')\\\n",
    "        .drop_duplicates(subset = ['Annotated Sequence', 'probe'])\\\n",
    "        [['Annotated Sequence', 'probe', 'RT [min]']]\n",
    "    alignDF = alignDF.pivot(index = 'Annotated Sequence', columns = 'probe', values = 'RT [min]')\\\n",
    "        .reset_index(drop = False)\n",
    "    alignDF.columns.name = None\n",
    "    alignDF.columns = ['Annotated Sequence', 'CBA_RT', 'CBPA_RT']\n",
    "\n",
    "    # find correlation between matched entries\n",
    "    model = RANSACRegressor()\n",
    "    trainData = alignDF.loc[alignDF[['CBA_RT', 'CBPA_RT']].notnull().sum(axis = 1) == 2,\n",
    "                                   ['CBA_RT', 'CBPA_RT']].values\n",
    "    model.fit(trainData[:, 0].reshape((-1,1)), trainData[:, 1].reshape((-1,1)))\n",
    "    print('Rsq =', model.score(trainData[:, 0].reshape((-1,1)), trainData[:, 1].reshape((-1,1))))\n",
    "    print('slope =', model.estimator_.coef_[0][0], ', intercept =', model.estimator_.intercept_[0])\n",
    "    plt.scatter(trainData[model.inlier_mask_, 0], trainData[model.inlier_mask_, 1], \n",
    "                color = 'cornflowerblue', alpha = '0.2')\n",
    "    plt.scatter(trainData[np.logical_not(model.inlier_mask_), 0], trainData[np.logical_not(model.inlier_mask_), 1], \n",
    "                color = 'orange', alpha = '0.2')\n",
    "    plt.xlabel('CBA RT [min]')\n",
    "    plt.ylabel('CBPA RT [min]')\n",
    "    plt.plot([20, 120], [20, 120], 'r--')\n",
    "    plt.legend(['identity line', 'data (inlier)', 'data (outlier)'])\n",
    "    plt.title('CBA/CBPA alignment plot')\n",
    "    plt.show()\n",
    "\n",
    "    # impute missing value using the correlation found\n",
    "    RTDF = alignDF.copy()\n",
    "    for index, row in RTDF.loc[RTDF[['CBA_RT', 'CBPA_RT']].notnull().sum(axis = 1) == 1].iterrows():\n",
    "        if pd.isnull(row['CBPA_RT']):\n",
    "            RTDF.loc[index, 'CBPA_RT'] = model.estimator_.coef_[0][0]*row['CBA_RT']+model.estimator_.intercept_[0]\n",
    "        else:\n",
    "            RTDF.loc[index, 'CBA_RT'] = (row['CBPA_RT']-model.estimator_.intercept_[0])/model.estimator_.coef_[0][0]\n",
    "    print('sanity check: after imputation, missing value summary')\n",
    "    print(RTDF[['CBA_RT', 'CBPA_RT']].isnull().sum(axis = 1).value_counts())\n",
    "\n",
    "    # construct m/z table, then merge them with filled RT\n",
    "    massDF = allDF.loc[(allDF['Confidence'] == 'High')\\\n",
    "                      & (allDF['Modifications'].apply(lambda s: pd.notnull(s) and 'si' in s.lower()))]\\\n",
    "        .sort_values(by = 'XCorr')\\\n",
    "        .drop_duplicates(subset = ['Annotated Sequence', 'probe'])\\\n",
    "        [['Annotated Sequence', 'probe', 'Theo. MH+ [Da]']]\n",
    "    massDF = massDF.pivot(index = 'Annotated Sequence', columns = 'probe', values = 'Theo. MH+ [Da]')\\\n",
    "        .reset_index(drop = False)\n",
    "    massDF.columns.name = None\n",
    "    for index, row in massDF.loc[massDF[['CBA', 'CBPA']].isnull().sum(axis = 1) == 1].iterrows():\n",
    "        if pd.isnull(row['CBA']):\n",
    "            massDF.loc[index, 'CBA'] = row['CBPA']-77.0265\n",
    "        else:\n",
    "            massDF.loc[index, 'CBPA'] = row['CBA']+77.0265\n",
    "    # remove the extra proton\n",
    "    massDF[['CBA', 'CBPA']] -= 1.0079\n",
    "    massDF.columns = ['Annotated Sequence', 'CBA_mass', 'CBPA_mass']\n",
    "\n",
    "    fullDF = RTDF.merge(right = massDF, how = 'left', on = 'Annotated Sequence')\n",
    "    fullDF.head()\n",
    "    \n",
    "    # prepare array for feature extraction\n",
    "    CBARecord = []\n",
    "    for index, row in fullDF.iterrows():\n",
    "        for charge in range(2, 7):\n",
    "            mz = (row['CBA_mass']+charge*1.0079)/charge\n",
    "            CBARecord.append([mz, charge, row['CBA_RT'], row['Annotated Sequence']])\n",
    "    CBADF = pd.DataFrame.from_records(CBARecord, columns = ['mz', 'charge', 'rt', 'Annotated Sequence'])\n",
    "    CBADF = CBADF.sort_values('rt', ascending = True).reset_index(drop = True)\n",
    "\n",
    "    # extract cubes (3-D arrays of intensity, m/z, and time) for quantification\n",
    "    CBAFinishedDict = parseSpectra(CBAmzmlPath, CBADF)\n",
    "\n",
    "    # separate signal from noise by phase\n",
    "    CBASeparatedDict = separateSignalNoise(CBAFinishedDict)\n",
    "\n",
    "    # quantification by FMPI (First Model Peak Intensity)\n",
    "    CBADF['FMPI'] = float('nan')\n",
    "    CBADF['mz'] = CBADF['mz'].apply(lambda x: str(round(x, 4)))\n",
    "    for index, row in CBADF.iterrows():\n",
    "        targetKeyList = [k for k in CBASeparatedDict.keys() if k[1] == row['mz'] and k[2] == row['charge']]\n",
    "        if len(targetKeyList) > 0:\n",
    "            targetKey = targetKeyList[0]\n",
    "            targetSpectrumList = CBASeparatedDict[targetKey]['signal']\n",
    "            FMPIList = []\n",
    "            for spectrum in targetSpectrumList:\n",
    "                quickFit = quickBrainpyRegularFit(spectrum, row['Annotated Sequence'], row['charge'], 'CBA')\n",
    "                FMPIList.append(quickFit[1][0])\n",
    "            CBADF.loc[index, 'FMPI'] = max(FMPIList)\n",
    "\n",
    "    # sanity check\n",
    "    CBADF = CBADF.loc[CBADF['FMPI'].notnull()]\n",
    "    print('CBA has', CBADF.shape[0], 'rows left')\n",
    "    \n",
    "    # prepare array for feature extraction\n",
    "    CBPARecord = []\n",
    "    for index, row in fullDF.iterrows():\n",
    "        for charge in range(2, 7):\n",
    "            mz = (row['CBPA_mass']+charge*1.0079)/charge\n",
    "            CBPARecord.append([mz, charge, row['CBPA_RT'], row['Annotated Sequence']])\n",
    "    CBPADF = pd.DataFrame.from_records(CBPARecord, columns = ['mz', 'charge', 'rt', 'Annotated Sequence'])\n",
    "    CBPADF = CBPADF.sort_values('rt', ascending = True).reset_index(drop = True)\n",
    "\n",
    "    # extract cubes (3-D arrays of intensity, m/z, and time) for quantification\n",
    "    CBPAFinishedDict = parseSpectra(CBPAmzmlPath, CBPADF)\n",
    "\n",
    "    # separate signal from noise by phase\n",
    "    CBPASeparatedDict = separateSignalNoise(CBPAFinishedDict)\n",
    "\n",
    "    # quantification by FMPI (First Model Peak Intensity)\n",
    "    CBPADF['FMPI'] = float('nan')\n",
    "    CBPADF['mz'] = CBPADF['mz'].apply(lambda x: str(round(x, 4)))\n",
    "    for index, row in CBPADF.iterrows():\n",
    "        targetKeyList = [k for k in CBPASeparatedDict.keys() if k[1] == row['mz'] and k[2] == row['charge']]\n",
    "        if len(targetKeyList) > 0:\n",
    "            targetKey = targetKeyList[0]\n",
    "            targetSpectrumList = CBPASeparatedDict[targetKey]['signal']\n",
    "            FMPIList = []\n",
    "            for spectrum in targetSpectrumList:\n",
    "                quickFit = quickBrainpyRegularFit(spectrum, row['Annotated Sequence'], row['charge'], 'CBPA')\n",
    "                FMPIList.append(quickFit[1][0])\n",
    "            CBPADF.loc[index, 'FMPI'] = max(FMPIList)\n",
    "\n",
    "    # sanity check\n",
    "    CBPADF = CBPADF.loc[CBPADF['FMPI'].notnull()]\n",
    "    print('CBPA has', CBPADF.shape[0], 'rows left')\n",
    "    \n",
    "    # in-house quantification\n",
    "    tmpDF1 = CBADF.groupby('Annotated Sequence')['FMPI'].sum().reset_index()\n",
    "    tmpDF1.columns = ['Annotated Sequence', 'FMPI_CBA']\n",
    "    tmpDF2 = CBPADF.groupby('Annotated Sequence')['FMPI'].sum().reset_index()\n",
    "    tmpDF2.columns = ['Annotated Sequence', 'FMPI_CBPA']\n",
    "    resultDF = tmpDF1.merge(tmpDF2, on = 'Annotated Sequence', how = 'outer')\n",
    "    resultBothDF = resultDF.loc[resultDF.isnull().sum(axis = 1) == 0]\n",
    "    print('in-house quantification NaN count')\n",
    "    print(resultDF.isnull().sum())\n",
    "\n",
    "    # PD quantification\n",
    "    DF = allDF.loc[(allDF['Confidence'] == 'High')\\\n",
    "                      & (allDF['Modifications'].apply(lambda s: pd.notnull(s) and 'si' in s.lower()))]\n",
    "    PADF = DF.sort_values(by = 'XCorr')\\\n",
    "        .drop_duplicates(subset = ['Annotated Sequence', 'probe'])\\\n",
    "        [['Annotated Sequence', 'Theo. MH+ [Da]', 'Charge', 'Precursor Abundance', 'probe']]\n",
    "    refDF = PADF.groupby(['probe', 'Annotated Sequence'])['Precursor Abundance'].sum()\\\n",
    "        .reset_index().pivot(index = 'Annotated Sequence', columns = 'probe', values = 'Precursor Abundance')\\\n",
    "        .reset_index()\n",
    "    refDF.columns.name = None\n",
    "    refBothDF = refDF.loc[refDF.isnull().sum(axis = 1) == 0]\n",
    "    print('PD quantification NaN count')\n",
    "    print(refDF.isnull().sum())\n",
    "\n",
    "    # plot side-by-side for comparison\n",
    "    fig, ax = plt.subplots(ncols = 3, nrows = 1, figsize = (15, 5))\n",
    "\n",
    "    # reference: PD quantification\n",
    "    ax[0].scatter(refBothDF['CBA'].apply(np.log10), \n",
    "                refBothDF['CBPA'].apply(np.log10),\n",
    "               color = 'cornflowerblue', alpha = 0.2)\n",
    "    ax[0].plot([3, 8], [3, 8], 'r--')\n",
    "    ax[0].legend(['identity line', 'data'], loc = 'lower right')\n",
    "    ax[0].set_xlabel('CBA log10(abundance)')\n",
    "    ax[0].set_ylabel('CBPA log10(abundance)')\n",
    "    ax[0].set_title('PD quantification, n = '+str(refBothDF.shape[0]))\n",
    "\n",
    "    # in-house quantification\n",
    "    ax[1].scatter(resultBothDF['FMPI_CBA'].apply(np.log10), \n",
    "                resultBothDF['FMPI_CBPA'].apply(np.log10),\n",
    "               color = 'cornflowerblue', alpha = 0.2)\n",
    "    ax[1].plot([3, 8], [3, 8], 'r--')\n",
    "    ax[1].legend(['identity line', 'data'], loc = 'lower right')\n",
    "    ax[1].set_xlabel('CBA log10(abundance)')\n",
    "    ax[1].set_ylabel('CBPA log10(abundance)')\n",
    "    ax[1].set_title('In-house quantification, n = '+str(resultBothDF.shape[0]))\n",
    "    \n",
    "    # plot\n",
    "    MVDF = alignDF[['CBA_RT', 'CBPA_RT']].isnull().sum(axis = 1).value_counts()\n",
    "    barPos = np.arange(1)\n",
    "    barWidth = 0.35\n",
    "    ax[2].bar(x = barPos, height = [MVDF[0]], width = barWidth, bottom = 0)\n",
    "    ax[2].bar(x = barPos, height = [MVDF[1]], width = barWidth, bottom = [MVDF[0]])\n",
    "    ax[2].legend(['0 missing value', '1 missing value', '2 missing value'])\n",
    "    ax[2].set_title('missing value counts using MS2 RT')\n",
    "    ax[2].set_ylabel('count')\n",
    "    ax[2].set_xlim([-1, 1])\n",
    "    ax[2].set_xticklabels([])\n",
    "\n",
    "    # adjustment\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('download.png', dpi = 600)\n",
    "    plt.show()\n",
    "    \n",
    "    return resultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "G23BCh-zKyzG"
   },
   "outputs": [],
   "source": [
    "resultDF.to_csv(os.path.join(working_directory_path, 'DKM102_HPG_CF_quant.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8A7SbBuj2Aqw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CBA_CPA_alignment_DKM102+106.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
